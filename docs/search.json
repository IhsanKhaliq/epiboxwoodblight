[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 epibxb authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/a_01_Visualise_data.html","id":"import-disease-data-data","dir":"Articles","previous_headings":"","what":"Import disease data data","title":"Data visualisation","text":"Import disease data recorded Lowgap & Lamsburg sites","code":"disease_dat <- read_excel(system.file(   \"extdata\",   \"NC_disease_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(replicate = as.factor(replicate)) %>%   dplyr::mutate(treatment = as.factor(treatment)) %>%   dplyr::mutate(total_count = as.integer(total_count)) %>%   dplyr::mutate(month = as.factor(months(date_in))) %>%   dplyr::mutate(spev_duration = as.integer(difftime(date_out, date_in))) %>%   relocate(month, .after = date_out) %>%   na.omit() %>%   group_by(     year,     location,     spread_event,     month,     treatment,     date_in,     date_out,     cultivar,     spev_duration   ) %>%   summarise(total_count = sum(total_count))"},{"path":"/articles/a_01_Visualise_data.html","id":"import-weather-data","dir":"Articles","previous_headings":"","what":"Import weather data","title":"Data visualisation","text":"","code":"# Filter rainy periods to calculate average wind speed, wind direction & temperature wet period weather_dat_rain <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   select(year,          wind_speed,          wind_direction,          temperature,          precipitation,          location,          spread_event) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(rain_duration = as.integer(precipitation > 0)) %>%   filter(precipitation > 0) %>%   group_by(year, location, spread_event) %>%   summarise(     total_rain = round(sum(precipitation), 5),     mean_ws = round(mean(wind_speed), 2),     rain_duration = round(sum(rain_duration * 15 / 60), 2),     mean_wd = round(circular.averaging(wind_direction), 2),     mean_temp = round(mean(temperature), 2)   )  # Filter rainless periods to calculate mean RH weather_dat_no_rain <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   select(     year,     relative_humidity,     leaf_wetness_duration,     precipitation,     location,     spread_event,     date   ) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   filter(precipitation == 0) %>%   group_by(year, location, spread_event) %>%   summarise(mean_rh = round(mean(relative_humidity * 100), 2))  # Combine data weather_dat_comb <-   left_join(weather_dat_rain,             weather_dat_no_rain,             by = c(\"year\", \"location\", \"spread_event\"))  # Leaf wetness duration both inside and outside rainy periods weather_wet <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   group_by(year, location, spread_event) %>%   summarise(lwd_duration = round(sum(leaf_wetness_duration / 60), 2))  weather_dat <-   left_join(weather_dat_comb,             weather_wet,             by = c(\"year\", \"location\", \"spread_event\"))  # Divide week 1 of 2014 rain/rain duration/wetness duration by 4 & that of week 2 & 3 by 3 to convert to per week data because the duration of spread event was 4 and 3 weeks, respectively.  weather_dat <- weather_dat %>%   mutate(     total_rain = ifelse(       year == \"2017\" & spread_event == \"1\",       total_rain / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         total_rain / 3,         total_rain       )     ),     rain_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       rain_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         rain_duration / 3,         rain_duration       )     ),     lwd_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       lwd_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         lwd_duration / 3,         lwd_duration       )     )   )"},{"path":"/articles/a_01_Visualise_data.html","id":"cobmine-weather-disease-data","dir":"Articles","previous_headings":"","what":"Cobmine weather & disease data","title":"Data visualisation","text":"Combine weather disease data","code":"dat_NC <-   left_join(disease_dat,             weather_dat,             by = c(\"year\", \"location\", \"spread_event\")) %>%   # Replace NA with zero because NA are introduced due to data munging. Original values were zero   dplyr::mutate(total_rain = replace_na(total_rain, 0)) %>%   dplyr::mutate(rain_duration = replace_na(rain_duration, 0))  # Since we filtered data separately for precipitation and then without precipitation, NAs are introduced. In this step, data (in which values were added manually) is imported  dat_missing <- read_excel(system.file(   \"extdata\",   \"NC_missing_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event))  # Combine data to replace NA values with distinct data dat_nc <-   left_join(dat_NC, dat_missing, by = c(\"year\", \"location\", \"spread_event\")) %>%   mutate(mean_ws = coalesce(mean_ws.x, mean_ws.y)) %>%   select(-mean_ws.x, -mean_ws.y) %>%   mutate(mean_temp = coalesce(mean_temp.x, mean_temp.y)) %>%   select(-mean_temp.x, -mean_temp.y) %>%   mutate(mean_rh = coalesce(mean_rh.x, mean_rh.y)) %>%   select(-mean_rh.x, -mean_rh.y) %>%   mutate(mean_wd = coalesce(mean_wd.x, mean_wd.y)) %>%   select(-mean_wd.x, -mean_wd.y) %>%   mutate(lwd_duration = coalesce(lwd_duration.x, lwd_duration.y)) %>%   select(-lwd_duration.x, -lwd_duration.y) %>%   distinct()  dat_nc <- dat_nc %>%   mutate(daily_rain = round(total_rain/spev_duration, 2),          daily_lwd  = round(lwd_duration/spev_duration, 2))    # Filter out mulch treatment. Use non-mulch and CP only. dat_nc_ncb <- dat_nc %>%   filter(treatment != \"mulch\", treatment != \"between_row\") # filter non-mulch, CP and between row treatments data  # Data considering only CP treatment dat_cp <- dat_nc %>%   filter(treatment == \"CP\")  # Data considering only leaf debris treatment dat_ld <- dat_nc %>%   filter(treatment == \"non_mulch\")  # Data considering only between row treatment dat_br <- dat_nc %>%   filter(treatment == \"between_row\")  # Data for Lambsburg site only dat_lambsburg <- dat_nc %>%   filter(location == \"Lambsburg\") %>%   filter(treatment != \"mulch\", treatment != \"between_row\")"},{"path":"/articles/a_01_Visualise_data.html","id":"histogram","dir":"Articles","previous_headings":"","what":"Histogram","title":"Data visualisation","text":"Histogram plot visualize distribution number infected leaves per plant.","code":"ggplot(dat_nc_ncb, aes(x = total_count)) +   geom_histogram(binwidth = 2,                  fill = \"steelblue\",                  alpha = 0.7) +   xlab(\"Number of infected leaves\")"},{"path":"/articles/a_01_Visualise_data.html","id":"infected-leaf-count-per-week","dir":"Articles","previous_headings":"","what":"Infected leaf count per week","title":"Data visualisation","text":"","code":"dat_week <- dat_nc_ncb %>%   mutate(date_in = format(date_in, \"%m/%d\")) %>%   group_by(year, date_in) %>%   arrange(year, date_in, total_count) %>%   ungroup() %>%   mutate(date_in = as.factor(date_in)) %>%   mutate(treatment = recode(treatment,                             \"CP\" = \"Infected canopies\",                             \"non_mulch\" = \"Leaf debris\")) %>%   rename(\"Inoculum source\" = treatment)  dates_weeks <- dat_week |>   mutate(date = mdy(paste0(date_in, year)),          week = week(date))   min_week <- min(dates_weeks$week) max_week <- max(dates_weeks$week)  year_breaks <- 2017:2014 |>   set_names() |>   map(\\(year_n) {     year_dat <- dates_weeks |>       filter(year == year_n) |>       select(date_in, week) |>       unique()          week_map <- character(max_week - min_week + 1)     names(week_map) <- seq(min_week, max_week)          week_map[as.character(year_dat$week)] <-       as.character(year_dat$date_in)               week_map        })   p <- dates_weeks |>   mutate(week = factor(week),          `Inoculum source` = factor(`Inoculum source`)) |>   nest(data = -year) |>   mutate(pl = map2(data, year, \\(data, year) {     # browser()          ggplot(data, aes(x = week, y = total_count, fill = `Inoculum source`)) +       geom_col() +       scale_x_discrete(labels = year_breaks[[as.character(year)]],                        drop = FALSE) +       facet_wrap(year, scales = \"free_y\", strip.position = \"right\") +       scale_fill_manual(values = c(         \"Infected canopies\" = \"navyblue\",         \"Leaf debris\" = \"darkred\"       )) +       theme_few(base_size = 10) +       coord_cartesian(ylim = c(0, 1000))        })) |>   pull(pl) |>   wrap_plots(ncol = 1) +   plot_layout(guides = \"collect\") & xlab(NULL) & ylab(NULL) &   theme(     legend.position = \"top\",     axis.text.x = element_text(       angle = 90,       hjust = 1,       vjust = 0.5,       color = \"black\"     ),     axis.text.y = element_text(vjust = 0.5, color = \"black\"),     axis.title = element_text(color = \"black\"),     strip.text = element_text(face = \"bold\", color = \"black\")        )  p <-   p + labs(x = \"Date of detector plants placement in the field\") +   theme(axis.title.x = element_text(hjust = 0.5))  # Center x-axis label   p <- wrap_elements(p) +   labs(tag = \"Infected leaf count on detector plants in each monitoring week\") +   theme(plot.tag = element_text(size = rel(1), angle = 90),         plot.tag.position = \"left\") p ggsave(   here(\"man\", \"figures/p.eps\"),   plot = p,   width = 7,   height = 7,   units = \"in\",   dpi = 600,   device =  cairo_ps )  ggsave(   here(\"man\", \"figures/p.png\"),   plot = p,   width = 12,   height = 10,   units = \"in\",   dpi = 600,   device =  cairo_ps )"},{"path":"/articles/a_01_Visualise_data.html","id":"windroses-showing-wind-speed-direction-in-each-year","dir":"Articles","previous_headings":"","what":"Windroses showing wind speed & direction in each year","title":"Data visualisation","text":"","code":"fig_S <-   with(     dat_nc_ncb,     windrose(       mean_ws,       mean_wd,       year,       n_col = 2,       legend_title = \"Wind speed (m/s)\"     )   )  fig_S3 <-   fig_S +   scale_fill_viridis_d(name = \"Wind Speed (m/s)\", direction = -1) +   xlab(\"\") +   theme_pubclean(base_family = \"Arial\", base_size = 12) ## Scale for fill is already present. ## Adding another scale for fill, which will replace the existing scale. fig_S"},{"path":[]},{"path":"/articles/a_01_Visualise_data.html","id":"heatmap-for-leaf-wetness-duration-temperature-relationship","dir":"Articles","previous_headings":"Heatmaps","what":"Heatmap for leaf wetness duration & temperature relationship","title":"Data visualisation","text":"","code":"dat_lwd <-   dat_nc_ncb %>%   as_tibble() %>%   mutate(     mean_temp = cut_interval(mean_temp, n = 10, dig.lab = 5),     lwd_duration = cut_interval(lwd_duration, n = 10, dig.lab = 5),   ) %>%   group_by(mean_temp, lwd_duration) %>%   summarize(total_count = sum(total_count)) ## `summarise()` has grouped output by 'mean_temp'. You can override using the ## `.groups` argument. # function to standardize the labels generated by cut_interval standardize_cut_levels <- function(l, dig = 2) {   sapply(l, \\(s) {     m = gregexpr(\"\\\\d+\\\\.?\\\\d{0,}\", s)     m = regmatches(s, m)[[1]]     r = sub(m[1], trimws(sprintf(       paste0(\"%9.\", dig, \"f\"), as.numeric(m[1])     )), s)     sub(m[2], trimws(sprintf(       paste0(\"%9.\", dig, \"f\"), as.numeric(m[2])     )), r)   }) }   levels(dat_lwd$mean_temp) <-   standardize_cut_levels(levels(dat_lwd$mean_temp)) levels(dat_lwd$lwd_duration) <-   standardize_cut_levels(levels(dat_lwd$lwd_duration))   heatmap_lwd <- ggplot(dat_lwd, aes(mean_temp, lwd_duration)) +   geom_tile(aes(fill = total_count), color = \"black\") +   geom_text(aes(label = round(total_count, 1))) +   scale_fill_gradient(low = \"white\", high = \"red\") +   labs(x = \"Mean temperature (°C)\", y = \"Leaf wetness duration (h)\") +   guides(fill = \"none\") +   theme(panel.grid.major = element_blank()) +   theme_few(base_size = 12, base_family = \"Arial\")  heatmap_lwd"},{"path":"/articles/a_01_Visualise_data.html","id":"heatmap-for-rain-temperature-relationship","dir":"Articles","previous_headings":"Heatmaps","what":"Heatmap for rain & temperature relationship","title":"Data visualisation","text":"","code":"dat_rain <-   dat_nc_ncb %>%   as_tibble() %>%   mutate(     mean_temp = cut_interval(mean_temp, n = 10, dig.lab = 5),     total_rain = cut_interval(total_rain, n = 10, dig.lab = 5),   ) %>%   group_by(mean_temp, total_rain) %>%   summarize(total_count = sum(total_count)) ## `summarise()` has grouped output by 'mean_temp'. You can override using the ## `.groups` argument. # function to standardize the labels generated by cut_interval standardize_cut_levels <- function(l, dig = 2) {   sapply(l, \\(s) {     m = gregexpr(\"\\\\d+\\\\.?\\\\d{0,}\", s)     m = regmatches(s, m)[[1]]     r = sub(m[1], trimws(sprintf(       paste0(\"%9.\", dig, \"f\"), as.numeric(m[1])     )), s)     sub(m[2], trimws(sprintf(       paste0(\"%9.\", dig, \"f\"), as.numeric(m[2])     )), r)   }) }  levels(dat_rain$mean_temp) <-   standardize_cut_levels(levels(dat_rain$mean_temp)) levels(dat_rain$total_rain) <-   standardize_cut_levels(levels(dat_rain$total_rain))  heatmap_rain <- ggplot(dat_rain, aes(mean_temp, total_rain)) +   geom_tile(aes(fill = total_count), color = \"black\") +   geom_text(aes(label = round(total_count, 1))) +   scale_fill_gradient(low = \"white\", high = \"red\") +   labs(x = \"Mean temperature during rainy periods (°C)\", y = \"Total rain (mm)\") +   guides(fill = \"none\") +   theme(panel.grid.major = element_blank()) +   theme_few(base_size = 12, base_family = \"Arial\")  heatmap_rain"},{"path":"/articles/a_01_Visualise_data.html","id":"heatmap-for-rh-temperature-relationship","dir":"Articles","previous_headings":"Heatmaps","what":"Heatmap for RH & temperature relationship","title":"Data visualisation","text":"","code":"dat_RH <-   dat_nc_ncb%>%   as_tibble() %>%   mutate(     mean_temp = cut_interval(mean_temp, n = 10),     mean_rh = cut_interval(mean_rh, n = 10),   ) %>%   group_by(mean_temp, mean_rh) %>%   summarize(total_count = sum(total_count)) ## `summarise()` has grouped output by 'mean_temp'. You can override using the ## `.groups` argument. # function to standardize the labels generated by cut_interval standardize_cut_levels <- function(l, dig=2) {   sapply(l, \\(s) {     m = gregexpr(\"\\\\d+\\\\.?\\\\d{0,}\",s)     m = regmatches(s,m)[[1]]     r = sub(m[1], trimws(sprintf(paste0(\"%9.\", dig, \"f\"), as.numeric(m[1]))),s)     sub(m[2], trimws(sprintf(paste0(\"%9.\", dig, \"f\"), as.numeric(m[2]))),r)   }) }   levels(dat_RH$mean_temp) <- standardize_cut_levels(levels(dat_RH$mean_temp)) levels(dat_RH$mean_rh) <- standardize_cut_levels(levels(dat_RH$mean_rh))   heatmap_rh <- ggplot(dat_RH, aes(mean_temp, mean_rh)) +   geom_tile(aes(fill = total_count), color = \"black\") +   geom_text(aes(label = round(total_count, 1))) +   scale_fill_gradient(low = \"white\", high = \"red\") +   labs(x = \"Mean temperature (°C)\", y = \"Mean relative humidity (%)\") +   guides(fill = \"none\") +    theme(panel.grid.major = element_blank()) +   theme_few(base_size = 12, base_family = \"Arial\")   heatmap_rh"},{"path":"/articles/a_01_Visualise_data.html","id":"combined-rain-calendar-heatmap-lambsburg-lowgap","dir":"Articles","previous_headings":"Heatmaps","what":"Combined rain calendar heatmap (Lambsburg + Lowgap)","title":"Data visualisation","text":"","code":"df1 <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   dplyr::mutate(date = as.Date(date, \"%m/%d/%Y\")) %>%   dplyr::mutate(year = as.factor(year)) %>%   group_by(date, year) %>%   summarise(precipitation = round(sum(precipitation))) %>%   ungroup() ## `summarise()` has grouped output by 'date'. You can override using the ## `.groups` argument. # color ramp pubu <- RColorBrewer::brewer.pal(9, \"PuBu\") col_p <- colorRampPalette(pubu)  theme_calendar <- function() {   theme(     aspect.ratio = 1 / 2,          axis.title = element_blank(),     axis.ticks = element_blank(),     axis.text.y = element_blank(),     axis.text = element_text(),          panel.grid = element_blank(),     panel.background = element_blank(),          strip.background = element_blank(),     strip.text = element_text(face = \"bold\", size = 15),          legend.position = \"top\",     legend.text = element_text(hjust = .5),     legend.title = element_text(size = 9, hjust = 1),          plot.caption =  element_text(hjust = 1, size = 8),     panel.border = element_rect(       colour = \"grey\",       fill = NA,       size = 1     ),     plot.title = element_text(       hjust = .5,       size = 26,       face = \"bold\",       margin = margin(0, 0, 0.5, 0, unit = \"cm\")     ),     plot.subtitle = element_text(hjust = .5, size = 16)   ) }    dat_prr <- df1 %>%   rename(pr = precipitation) %>%   complete(date = seq(min(date),                       max(date),                       \"day\")) %>%   mutate(     weekday = lubridate::wday(date, label = T, week_start = 1),     month = lubridate::month(date, label = T, abbr = F),     week = isoweek(date),     day = day(date)   ) %>%   na.omit()  dat_prr <- mutate(   dat_prr,   week = case_when(     month == \"December\" & week == 1 ~ 53,     month == \"January\" &       week %in% 52:53 ~ 0,     TRUE ~ week   ),   pcat = cut(pr, c(-1, 0, 0.5, 1:5, 7, 9, 25, 81)),   text_col = ifelse(pcat %in% c(\"(7,9]\", \"(9,25]\"), \"white\", \"black\") )  calendar_combined_rain <- ggplot(dat_prr %>%                                    mutate(week = week - min(week),                                           .by = c(year, month)),                                  aes(weekday, -week, fill = pcat)) +   geom_tile(colour = \"white\", size = .4)  +   geom_text(aes(label = day, colour = text_col), size = 2.5) +   guides(fill = guide_colorsteps(     barwidth = 25,     barheight = .4,     title.position = \"top\"   )) +   scale_fill_manual(     values = c(\"white\", col_p(13)),     na.value = \"grey90\",     drop = FALSE   ) +   scale_colour_manual(values = c(\"black\", \"white\"), guide = \"none\") +   facet_grid(year ~ month,              scales = \"free\") +   labs(title = \" Daily rainfall during field trials (2014-2017)\",        subtitle = \"Rainfall\",        fill = \"mm\") +   theme_calendar()  calendar_combined_rain ggsave(here::here(\"man\", \"figures/calendar_combined_rain.png\")) ## Saving 12 x 12 in image ggsave(here::here(\"man\", \"figures/calendar_combined_rain.eps\"), device = cairo_ps) ## Saving 12 x 12 in image"},{"path":"/articles/a_01_Visualise_data.html","id":"combined-temperature-heatmap-lambsburg-lowgap","dir":"Articles","previous_headings":"Heatmaps","what":"Combined temperature heatmap (Lambsburg + Lowgap)","title":"Data visualisation","text":"","code":"df2 <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   dplyr::mutate(date = as.Date(date, \"%m/%d/%Y\")) %>%   dplyr::mutate(year = as.factor(year)) %>%   filter(precipitation > 0) %>%   group_by(date, year) %>%   summarise(temperature = mean(temperature)) %>%   ungroup() ## `summarise()` has grouped output by 'date'. You can override using the ## `.groups` argument. dat_tr <- df2 %>%   rename(tr = temperature) %>%   complete(date = seq(min(date),                       max(date),                       \"day\")) %>%   mutate(     weekday = lubridate::wday(date, label = T, week_start = 1),     month = lubridate::month(date, label = T, abbr = F),     week = isoweek(date),     day = day(date)   ) %>%   na.omit()  dat_tr <- mutate(   dat_tr,   week = case_when(     month == \"December\" & week == 1 ~ 53,     month == \"January\" &       week %in% 52:53 ~ 0,     TRUE ~ week   ),   pcat = cut(tr, c(1.8, 3:7, 9, 15, 22, 29)),   text_col = ifelse(pcat %in% c(\"(9,15]\", \"(15,22]\"), \"white\", \"black\") )   calendar_combined_temp <- ggplot(dat_tr %>%                                    mutate(week = week - min(week),                                           .by = c(year, month)),                                  aes(weekday,-week, fill = tr)) +   geom_tile(colour = \"white\", linewidth = 0.4) +   geom_text(aes(label = day), size = 2.5, colour = \"black\") + # Set text color to black   guides(fill = guide_colorsteps(     barwidth = 25,     barheight = 0.4,     title.position = \"top\"   )) +   scale_fill_steps2(     low = \"blue\",     high = \"red\",     midpoint = 22,     n.breaks = 10,     # Set the breaks to match the custom labels     breaks = c(3, 5, 8, 12, 15, 18, 20, 22, 25, 27),     # Use the labels argument to specify custom labels without decimal places     labels = c(3, 5, 8, 12, 15, 18, 20, 22, 25, 27)   ) +   facet_grid(year ~ month,              scales = \"free\") +   labs(title = \"Daily mean temperature during rainy periods in field trials (2014-2017)\",        subtitle = \"Temperature\",        fill = \"degree Celsius\") +   theme_calendar()  calendar_combined_temp ggsave(here::here(\"man\", \"figures/calendar_combined_temp.png\")) ## Saving 12 x 12 in image ggsave(here::here(\"man\", \"figures/calendar_combined_temp.eps\"), device = cairo_ps) ## Saving 12 x 12 in image"},{"path":[]},{"path":"/articles/a_01_Visualise_data.html","id":"during-rainy-periods","dir":"Articles","previous_headings":"Number of hours per week with relative humidity greater than 90% and mean temperature when relative humidity was greater than 90%","what":"During rainy periods","title":"Data visualisation","text":"","code":"weather_rh <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   mutate(day = day(date)) %>%   mutate(month = month(date)) %>%   mutate(relative_humidity = relative_humidity * 100) %>%   mutate(     spread_event =  as.factor(spread_event),     year = as.factor(year),     location = as.factor(location)   ) %>%   mutate(lw_rh = case_when(relative_humidity > 90 ~ 1,                            TRUE ~ 0)) %>%   filter(lw_rh > 0) %>%   group_by(year, location, spread_event) %>%   summarise(temp_rh_lwd = mean(temperature),             # mean temperature when RH was > 90%             lw_rh_count = n() * 15 / 60) # Weekly number of hours when RH was greater than 90% ## `summarise()` has grouped output by 'year', 'location'. You can override using ## the `.groups` argument. # Divide week 1 of 2017 rain/rain duration/wetness duration by 4 & that of week 2 & 3 by 3 because the duration of spread event was 4 and 3 weeks, respectively.  weather_rh <- weather_rh %>%   mutate(     lw_rh_count = ifelse(       year == \"2017\" & spread_event == \"1\",        lw_rh_count/4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),          lw_rh_count/3,          lw_rh_count        )     ))   disease_dat2 <- disease_dat %>%  filter(treatment != \"mulch\", treatment != \"between_row\") %>%    group_by(year, location, spread_event, spev_duration) %>%   summarise(total_count = sum(total_count)) ## `summarise()` has grouped output by 'year', 'location', 'spread_event'. You can ## override using the `.groups` argument. # Combine weather data with disease data disease_dat_rh <- left_join(disease_dat2, weather_rh, by = c(\"year\", \"location\", \"spread_event\")) %>%   mutate(daily_lw_rh_count = lw_rh_count/spev_duration)      # openxlsx::write.xlsx(disease_dat_rh, \"rh_dat_rainy_period.xlsx\")"},{"path":"/articles/a_01_Visualise_data.html","id":"heatmap-for-hours-with-rh-90-mean-temperature-during-rh-90","dir":"Articles","previous_headings":"Number of hours per week with relative humidity greater than 90% and mean temperature when relative humidity was greater than 90%","what":"Heatmap for hours with RH >90% & mean temperature during RH >90%","title":"Data visualisation","text":"","code":"dat_RH2 <-   disease_dat_rh %>%   as_tibble() %>%   mutate(     temp_rh_lwd= cut_interval(temp_rh_lwd, n = 10),     lw_rh_count = cut_interval(lw_rh_count, n = 10),   ) %>%   group_by(temp_rh_lwd, lw_rh_count) %>%   summarize(total_count = sum(total_count)) ## `summarise()` has grouped output by 'temp_rh_lwd'. You can override using the ## `.groups` argument. # function to standardize the labels generated by cut_interval standardize_cut_levels <- function(l, dig=2) {   sapply(l, \\(s) {     m = gregexpr(\"\\\\d+\\\\.?\\\\d{0,}\",s)     m = regmatches(s,m)[[1]]     r = sub(m[1], trimws(sprintf(paste0(\"%9.\", dig, \"f\"), as.numeric(m[1]))),s)     sub(m[2], trimws(sprintf(paste0(\"%9.\", dig, \"f\"), as.numeric(m[2]))),r)   }) }   levels(dat_RH2$temp_rh_lwd) <- standardize_cut_levels(levels(dat_RH2$temp_rh_lwd)) levels(dat_RH2$lw_rh_count) <- standardize_cut_levels(levels(dat_RH2$lw_rh_count))   heatmap_rh_lw <- ggplot(dat_RH2, aes(temp_rh_lwd, lw_rh_count)) +   geom_tile(aes(fill = total_count), color = \"black\") +   geom_text(aes(label = round(total_count, 1))) +   scale_fill_gradient(low = \"white\", high = \"red\") +   labs(x = \"Mean temperature (°C)\", y = \"Hours relative humidity exceeding 90%\") +   guides(fill = \"none\") +    theme(panel.grid.major = element_blank()) +   theme_few(base_size = 12, base_family = \"Arial\")   heatmap_rh_lw"},{"path":[]},{"path":"/articles/a_01_Visualise_data.html","id":"import-weather-data-1","dir":"Articles","previous_headings":"Visualise weather data for the past 12-years to help interpret temporal patterns of boxwood blight development in Virginia","what":"import weather data","title":"Data visualisation","text":"","code":"weather_va <- get_power(       community = \"ag\",       lonlat = c(-80.7666, 36.5833),       pars = c(\"RH2M\", \"T2M\", \"PRECTOTCORR\"),       dates = c(\"2010-01-01\", \"2021-12-31\"),       temporal_api = \"hourly\"     ) %>% mutate(date = as.Date(sprintf('%04d-%02d-%02d', YEAR, MO, DY))) %>%   mutate(month = format(date, \"%B\")) %>%   mutate(julian_day = yday(date)) %>%   filter(date > \"2009-12-31\") %>% rename_with(~ \"rainfall\", .cols = matches(\"PRECTOTCORR\")) %>%   rename_with(~ \"temp\", .cols = matches(\"T2M\")) %>%   rename_with(~ \"rh\", .cols = matches(\"RH2M\"))    #openxlsx::write.xlsx(weather_va, \"dailyWEATHER.xlsx\")  # openxlsx::write.xlsx(weather_va, \"daily_weather2010-2020_Lambsburg.xlsx\")"},{"path":"/articles/a_01_Visualise_data.html","id":"plot-monthly-mean-weather-data-for-the-trial-site-in-virginia","dir":"Articles","previous_headings":"Visualise weather data for the past 12-years to help interpret temporal patterns of boxwood blight development in Virginia","what":"Plot monthly mean weather data for the trial site in Virginia","title":"Data visualisation","text":"","code":"# Get monthly data for 10 years weather_va_monthly <- weather_va %>%   group_by(YEAR, month) %>%   summarise(     total_rain = round(sum(rainfall), 2),     mean_temp = round(mean(temp), 2),     mean_rh = round(mean(rh), 2)   ) ## `summarise()` has grouped output by 'YEAR'. You can override using the ## `.groups` argument. # Convert full month names to abbreviated names weather_va_monthly$month <- factor(weather_va_monthly$month, levels = month.name, labels = month.abb)   fig_month_va <- ggplot(weather_va_monthly, aes(x = month)) +     geom_bar(aes(y = total_rain/4, fill = \"Rainfall (mm)\"), stat = \"identity\") +     geom_line(aes(y = mean_temp, color = \"Temperature (°C)\", group = 1),                linetype = \"dashed\") +     geom_line(aes(y = mean_rh, color = \"Relative Humidity (%)\", group = 1),                linetype = \"dashed\") +     geom_point(aes(y = mean_temp, color = \"Temperature (°C)\"), shape = 16, size = 1.5) + # Add solid circles for temperature line     geom_point(aes(y = mean_rh, color = \"Relative Humidity (%)\"), shape = 16, size = 1.5) + # Add solid circles for relative humidity line     scale_y_continuous(         name = \"Temperature and relative humidity\",         sec.axis = sec_axis(~.*4, name = \"Rainfall\")     ) +     scale_color_manual(         name = \"\",         values = c(\"Temperature (°C)\" = \"navyblue\", \"Relative Humidity (%)\" = \"darkred\")     ) +     scale_fill_manual(name = \"\", values = \"darkgoldenrod\") +     labs(x = \"\", title = \"Lambsburg, Virginia\") +     theme_few() +      theme(         text = element_text(size = 14),         axis.text.x = element_text(angle = 90, vjust = 0.5),         legend.position = \"bottom\",         plot.title = element_text(hjust = 0.5)     ) +      facet_wrap(~YEAR)  fig_month_va ggsave(   here(\"man\", \"figures/fig_month_va.png\"),   plot = fig_month_va,   width = 12,   height = 7.5,   units = \"in\",   dpi = 600 )"},{"path":"/articles/a_01_Visualise_data.html","id":"plot-daily-hours-with-rh-90-and-mean-temperature-during-those-hours-for-virginia-trial-site","dir":"Articles","previous_headings":"Visualise weather data for the past 12-years to help interpret temporal patterns of boxwood blight development in Virginia","what":"Plot daily hours with RH >90% and mean temperature during those hours for Virginia trial site","title":"Data visualisation","text":"","code":"weather_va_daily <- weather_va %>%       mutate(days_month = days_in_month(as.Date(paste(YEAR, MO, 1, sep = \"-\")))) %>%   group_by(YEAR, month) %>%        mutate(LW = case_when(rh > 90 ~ 1,                             TRUE ~ 0)) %>%       filter(LW > 0) %>%       summarise(Air_LWD = mean(temp),                 LWD = n()                 ) ## `summarise()` has grouped output by 'YEAR'. You can override using the ## `.groups` argument. # Convert full month names to abbreviated names weather_va_daily$month <- factor(weather_va_daily$month, levels = month.name, labels = month.abb)  fig_month_va_rh <- ggplot(weather_va_daily, aes(x = month)) +   geom_bar(aes(y = LWD / 4, fill = \"Hours relative humidity above 90%\"), stat = \"identity\") +   geom_line(aes(y = Air_LWD, color = \"Temperature (°C)\", group = 1),             linetype = \"dashed\") +   geom_point(aes(y = Air_LWD)) +   # geom_line(aes(y = mean_rh, color = \"Relative Humidity (%)\", group = 1),    #           linetype = \"dashed\") +   # geom_point(aes(y = mean_rh), shape = 18) +   #scale_x_discrete(limits = month.name) +   scale_y_continuous(     name = \"\",     sec.axis = sec_axis(~.*4, name = \"Hours relative humidity above 90%\")   ) +   scale_color_manual(     name = \"\",     values = c(\"Temperature (°C)\" = \"black\")   ) +   scale_fill_manual(name = \"\", values = \"darkgoldenrod\") +   labs(x = \"\", title = \"Lambsburg, Virginia\") +   theme_few() +    theme(     text = element_text(size = 10),     axis.text.x = element_text(angle = 90, vjust = 0.5),     legend.position = \"bottom\",     plot.title = element_text(hjust = 0.5)   ) +    facet_wrap(~YEAR)  fig_month_va_rh ggsave(   here(\"man\", \"figures/fig_month_va_rh.png\"),   plot = fig_month_va_rh,   width = 9,   height = 6,   units = \"in\",   dpi = 1000  )"},{"path":[]},{"path":"/articles/a_01_Visualise_data.html","id":"import-weather-data-2","dir":"Articles","previous_headings":"Visualise weather data for the past decade for the trial site in North Carolina","what":"Import weather data","title":"Data visualisation","text":"","code":"weather_nc <- get_power(       community = \"ag\",       lonlat = c(-80.8333, 36.5166),       pars = c(\"RH2M\", \"T2M\", \"PRECTOTCORR\"),       dates = c(\"2010-01-01\", \"2021-12-31\"),       temporal_api = \"hourly\"     ) %>% mutate(date = as.Date(sprintf('%04d-%02d-%02d', YEAR, MO, DY))) %>%   mutate(month = format(date, \"%B\")) %>%   mutate(julian_day = yday(date)) %>%   filter(date > \"2009-12-31\") %>% rename_with(~ \"rainfall\", .cols = matches(\"PRECTOTCORR\")) %>%   rename_with(~ \"temp\", .cols = matches(\"T2M\")) %>%   rename_with(~ \"rh\", .cols = matches(\"RH2M\"))"},{"path":"/articles/a_01_Visualise_data.html","id":"plot-monthly-mean-data-for-the-trial-site-in-north-carolina","dir":"Articles","previous_headings":"","what":"Plot monthly mean data for the trial site in North Carolina","title":"Data visualisation","text":"","code":"# Get monthly data for 12 years weather_nc_monthly <- weather_nc %>%   group_by(YEAR, month) %>%   summarise(     total_rain = round(sum(rainfall), 2),     mean_temp = round(mean(temp), 2),     mean_rh = round(mean(rh), 2)   ) ## `summarise()` has grouped output by 'YEAR'. You can override using the ## `.groups` argument. # Convert full month names to abbreviated names weather_nc_monthly$month <- factor(weather_nc_monthly$month, levels = month.name, labels = month.abb)  fig_month_nc <- ggplot(weather_nc_monthly, aes(x = month)) +     geom_bar(aes(y = total_rain/4, fill = \"Rainfall (mm)\"), stat = \"identity\") +     geom_line(aes(y = mean_temp, color = \"Temperature (°C)\", group = 1),                linetype = \"dashed\") +     geom_line(aes(y = mean_rh, color = \"Relative Humidity (%)\", group = 1),                linetype = \"dashed\") +     geom_point(aes(y = mean_temp, color = \"Temperature (°C)\"), shape = 16, size = 1.5) + # Add solid circles for temperature line     geom_point(aes(y = mean_rh, color = \"Relative Humidity (%)\"), shape = 16, size = 1.5) + # Add solid circles for relative humidity line     scale_y_continuous(         name = \"Temperature and relative humidity\",         sec.axis = sec_axis(~.*4, name = \"Rainfall\")     ) +     scale_color_manual(         name = \"\",         values = c(\"Temperature (°C)\" = \"navyblue\", \"Relative Humidity (%)\" = \"darkred\")     ) +     scale_fill_manual(name = \"\", values = \"darkgoldenrod\") +     labs(x = \"\", title = \"\") +     theme_few() +      theme(         text = element_text(size = 14),         axis.text.x = element_text(angle = 90, vjust = 0.5),         legend.position = \"bottom\",         plot.title = element_text(hjust = 0.5)     ) +      facet_wrap(~YEAR)  fig_month_nc ggsave(   here(\"man\", \"figures/fig_month_nc.png\"),   plot = fig_month_nc,   width = 12,   height = 7,   units = \"in\",   dpi = 600 )"},{"path":"/articles/a_01_Visualise_data.html","id":"plot-daily-hours-with-rh-90-and-mean-temperature-during-those-hours-for-north-carolina-trial-site","dir":"Articles","previous_headings":"","what":"Plot daily hours with RH >90% and mean temperature during those hours for North Carolina trial site","title":"Data visualisation","text":"","code":"weather_nc_daily <- weather_nc %>%       mutate(days_month = days_in_month(as.Date(paste(YEAR, MO, 1, sep = \"-\")))) %>%   group_by(YEAR, month) %>%        mutate(LW = case_when(rh > 90 ~ 1,                             TRUE ~ 0)) %>%       filter(LW > 0) %>%       summarise(Air_LWD = mean(temp),                 LWD = n()                 ) ## `summarise()` has grouped output by 'YEAR'. You can override using the ## `.groups` argument. # Convert full month names to abbreviated names weather_nc_daily$month <- factor(weather_nc_daily$month, levels = month.name, labels = month.abb)  fig_month_nc_rh <- ggplot(weather_nc_daily, aes(x = month)) +   geom_bar(aes(y = LWD/4, fill = \"Hours relative humidity above 90%\"), stat = \"identity\") +   geom_line(aes(y =Air_LWD, color = \"Temperature (°C)\", group = 1),              linetype = \"dashed\") +   geom_point(aes(y = Air_LWD)) +   # geom_line(aes(y = mean_rh, color = \"Relative Humidity (%)\", group = 1),    #           linetype = \"dashed\") +   # geom_point(aes(y = mean_rh), shape = 18) +   #scale_x_discrete(limits = month.name) +   scale_y_continuous(     name = \"\",     sec.axis = sec_axis(~.*4, name = \"Hours relative humidity above 90%\")   ) +   scale_color_manual(     name = \"\",     values = c(\"Temperature (°C)\" = \"black\")   ) +   scale_fill_manual(name = \"\", values = \"darkgoldenrod\") +   labs(x = \"\", title = \"Lowgap, North Carolina\") +   theme_few() +    theme(     text = element_text(size = 10),     axis.text.x = element_text(angle = 90, vjust = 0.5),     legend.position = \"bottom\",     plot.title = element_text(hjust = 0.5)   ) +    facet_wrap(~YEAR)  fig_month_nc_rh ggsave(   here(\"man\", \"figures/fig_month_nc_rh.eps\"),   plot = fig_month_nc_rh,   width = 9,   height = 6,   units = \"in\",   dpi = 600,   device =  cairo_ps )"},{"path":[]},{"path":"/articles/a_02_Fit_GLMMs.html","id":"import-disease-data-1","dir":"Articles","previous_headings":"Import disease data","what":"Import disease data","title":"Fit GLMMs","text":"","code":"disease_dat <- read_excel(system.file(   \"extdata\",   \"NC_disease_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(replicate = as.factor(replicate)) %>%   dplyr::mutate(treatment = as.factor(treatment)) %>%   dplyr::mutate(total_count = as.integer(total_count)) %>%   dplyr::mutate(month = as.factor(months(date_in))) %>%   dplyr::mutate(spev_duration = as.integer(difftime(date_out, date_in))) %>%   relocate(month, .after = date_out) %>%   na.omit() %>%   group_by(     year,     location,     spread_event,     month,     treatment,     date_in,     date_out,     cultivar,     spev_duration   ) %>%   summarise(total_count = sum(total_count))  #openxlsx::write.xlsx(disease_dat, \"Table S1.xlsx\", rowNames=FALSE)"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"import-weather-data","dir":"Articles","previous_headings":"Import disease data","what":"Import weather data","title":"Fit GLMMs","text":"","code":"# Filter rainy periods to calculate average wind speed, wind direction & temperature wet period weather_dat_rain <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   select(year,          wind_speed,          wind_direction,          temperature,          precipitation,          location,          spread_event) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(rain_duration = as.integer(precipitation > 0)) %>%   filter(precipitation > 0) %>%   group_by(year, location, spread_event) %>%   summarise(     total_rain = round(sum(precipitation), 5),     mean_ws = round(mean(wind_speed), 2),     rain_duration = round(sum(rain_duration * 15 / 60), 2),     mean_wd = round(circular.averaging(wind_direction), 2),     mean_temp = round(mean(temperature), 2)   )  # Filter rainless periods to calculate mean RH weather_dat_no_rain <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   select(     year,     relative_humidity,     leaf_wetness_duration,     precipitation,     location,     spread_event,     date   ) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   filter(precipitation == 0) %>%   group_by(year, location, spread_event) %>%   summarise(mean_rh = round(mean(relative_humidity * 100), 2))  # Combine data weather_dat_comb <-   left_join(weather_dat_rain,             weather_dat_no_rain,             by = c(\"year\", \"location\", \"spread_event\"))  # Leaf wetness duration both inside and outside rainy periods weather_wet <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   group_by(year, location, spread_event) %>%   summarise(lwd_duration = round(sum(leaf_wetness_duration / 60), 2))  weather_dat <-   left_join(weather_dat_comb,             weather_wet,             by = c(\"year\", \"location\", \"spread_event\"))  # Divide week 1 of 2014 rain/rain duration/wetness duration by 4 & that of week 2 & 3 by 3 to convert to per week data because the duration of spread event was 4 and 3 weeks, respectively.  weather_dat <- weather_dat %>%   mutate(     total_rain = ifelse(       year == \"2017\" & spread_event == \"1\",       total_rain / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         total_rain / 3,         total_rain       )     ),     rain_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       rain_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         rain_duration / 3,         rain_duration       )     ),     lwd_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       lwd_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         lwd_duration / 3,         lwd_duration       )     )   )"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"cobmine-weather-disease-data","dir":"Articles","previous_headings":"Import disease data","what":"Cobmine weather & disease data","title":"Fit GLMMs","text":"Combine weather disease data","code":"dat_NC <-   left_join(disease_dat,             weather_dat,             by = c(\"year\", \"location\", \"spread_event\")) %>%   # Replace NA with zero because NA are introduced due to data munging. Original values were zero   dplyr::mutate(total_rain = replace_na(total_rain, 0)) %>%   dplyr::mutate(rain_duration = replace_na(rain_duration, 0))  # Since we filtered data separately for precipitation and then without precipitation, NAs are introduced. In this step, data (in which values were added manually) is imported  dat_missing <- read_excel(system.file(   \"extdata\",   \"NC_missing_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event))  # Combine data to replace NA values with distinct data dat_nc <-   left_join(dat_NC, dat_missing, by = c(\"year\", \"location\", \"spread_event\")) %>%   mutate(mean_ws = coalesce(mean_ws.x, mean_ws.y)) %>%   select(-mean_ws.x, -mean_ws.y) %>%   mutate(mean_temp = coalesce(mean_temp.x, mean_temp.y)) %>%   select(-mean_temp.x, -mean_temp.y) %>%   mutate(mean_rh = coalesce(mean_rh.x, mean_rh.y)) %>%   select(-mean_rh.x, -mean_rh.y) %>%   mutate(mean_wd = coalesce(mean_wd.x, mean_wd.y)) %>%   select(-mean_wd.x, -mean_wd.y) %>%   mutate(lwd_duration = coalesce(lwd_duration.x, lwd_duration.y)) %>%   select(-lwd_duration.x, -lwd_duration.y) %>%   distinct() ## Warning in left_join(dat_NC, dat_missing, by = c(\"year\", \"location\", \"spread_event\")): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 50 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = ##   \"many-to-many\"` to silence this warning. dat_nc <- dat_nc %>%   mutate(daily_rain = round(total_rain/spev_duration, 2),          daily_lwd  = round(lwd_duration/spev_duration, 2))    # Filter out mulch treatment. Use non-mulch and CP only. dat_nc_ncb <- dat_nc %>%   filter(treatment != \"mulch\", treatment != \"between_row\") # filter non-mulch, CP and between row treatments data  # Data considering only CP treatment dat_cp <- dat_nc %>%   filter(treatment == \"CP\")  # Data considering only leaf debris treatment dat_ld <- dat_nc %>%   filter(treatment == \"non_mulch\")  # Data considering only between row treatment dat_br <- dat_nc %>%   filter(treatment == \"between_row\")  # Data for Lambsburg site only dat_lambsburg <- dat_nc %>%   filter(location == \"Lambsburg\") %>%   filter(treatment != \"mulch\", treatment != \"between_row\")"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"check-data","dir":"Articles","previous_headings":"Import disease data","what":"Check data","title":"Fit GLMMs","text":"Use set.seed() reproducibility purposes.","code":"kable(dat_nc_ncb,       format = \"html\",       table.attr = \"class='table table-hover'\") set.seed(42)"},{"path":[]},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_1-total-rain","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Mod_1 (Total rain)","title":"Fit GLMMs","text":"","code":"mod_1 <-   glmmTMB(total_count ~ total_rain +  (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_1) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ total_rain + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1163.1   1175.7   -577.6   1155.1      167  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance  Std.Dev.  ##  spread_event (Intercept) 6.689e-08 0.0002586 ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.198  ##  ## Conditional model: ##             Estimate Std. Error z value Pr(>|z|)     ## (Intercept) 2.148594   0.277974   7.729 1.08e-14 *** ## total_rain  0.039518   0.008408   4.700 2.60e-06 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_2-wind-speed","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Mod_2 (Wind speed)","title":"Fit GLMMs","text":"","code":"mod_2 <-   glmmTMB(total_count ~ mean_wd * mean_ws + (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_2) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ mean_wd * mean_ws + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1183.4   1202.2   -585.7   1171.4      165  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance Std.Dev. ##  spread_event (Intercept) 0.2581   0.508    ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.185  ##  ## Conditional model: ##                  Estimate Std. Error z value Pr(>|z|)     ## (Intercept)      4.475529   0.521003   8.590  < 2e-16 *** ## mean_wd         -0.003402   0.002498  -1.362  0.17330     ## mean_ws         -4.807255   1.666290  -2.885  0.00391 **  ## mean_wd:mean_ws  0.013986   0.011680   1.197  0.23116     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_3-wind-speed","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Mod_3 (Wind speed)","title":"Fit GLMMs","text":"","code":"mod_3 <-   glmmTMB(total_count ~ mean_wd + (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_3) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ mean_wd + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1187.9   1200.4   -589.9   1179.9      167  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance  Std.Dev.  ##  spread_event (Intercept) 1.126e-07 0.0003356 ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.168  ##  ## Conditional model: ##              Estimate Std. Error z value Pr(>|z|)     ## (Intercept)  3.845204   0.284833  13.500   <2e-16 *** ## mean_wd     -0.001804   0.001380  -1.307    0.191     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_4-leaf-wetness-duration","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Mod_4 (Leaf wetness duration)","title":"Fit GLMMs","text":"","code":"mod_4 <-   glmmTMB(total_count ~  lwd_duration +  (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_4) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ lwd_duration + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1162.3   1174.9   -577.2   1154.3      167  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance Std.Dev. ##  spread_event (Intercept) 0.4358   0.6601   ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.214  ##  ## Conditional model: ##              Estimate Std. Error z value Pr(>|z|)     ## (Intercept)   0.77909    0.51350   1.517    0.129     ## lwd_duration  0.03086    0.00605   5.101 3.38e-07 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_5-relative-humidity","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Mod_5 (Relative humidity)","title":"Fit GLMMs","text":"","code":"mod_5 <-   glmmTMB(total_count ~  mean_rh  + (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_5) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ mean_rh + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1152.6   1165.1   -572.3   1144.6      167  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance Std.Dev. ##  spread_event (Intercept) 0.9533   0.9764   ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.246  ##  ## Conditional model: ##             Estimate Std. Error z value Pr(>|z|)     ## (Intercept) -10.2932     2.3607  -4.360  1.3e-05 *** ## mean_rh       0.1645     0.0290   5.673  1.4e-08 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"mod_6-temperature","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"mod_6 (Temperature)","title":"Fit GLMMs","text":"","code":"mod_6 <-   glmmTMB(total_count ~  mean_temp + (1 | spread_event),           family = nbinom2,           data = dat_nc_ncb)  summary(mod_6) ##  Family: nbinom2  ( log ) ## Formula:          total_count ~ mean_temp + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1188.3   1200.8   -590.1   1180.3      167  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance Std.Dev. ##  spread_event (Intercept) 0.3913   0.6255   ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.177  ##  ## Conditional model: ##             Estimate Std. Error z value Pr(>|z|)    ## (Intercept)  2.82529    1.02370   2.760  0.00578 ** ## mean_temp    0.03357    0.05452   0.616  0.53810    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"fit-multivariate-glmms","dir":"Articles","previous_headings":"Fit univariate/bivariate glmms","what":"Fit multivariate glmms","title":"Fit GLMMs","text":"","code":"mod_7 <-   glmmTMB(     total_count ~ mean_rh + total_rain + mean_wd * mean_ws + mean_temp * lwd_duration + location + (1 | spread_event), family = nbinom2,     data = dat_nc_ncb   )  summary(mod_7) ##  Family: nbinom2  ( log ) ## Formula:           ## total_count ~ mean_rh + total_rain + mean_wd * mean_ws + mean_temp *   ##     lwd_duration + location + (1 | spread_event) ## Data: dat_nc_ncb ##  ##      AIC      BIC   logLik deviance df.resid  ##   1128.9   1166.6   -552.4   1104.9      159  ##  ## Random effects: ##  ## Conditional model: ##  Groups       Name        Variance  Std.Dev.  ##  spread_event (Intercept) 3.206e-08 0.0001791 ## Number of obs: 171, groups:  spread_event, 26 ##  ## Dispersion parameter for nbinom2 family (): 0.277  ##  ## Conditional model: ##                          Estimate Std. Error z value Pr(>|z|)     ## (Intercept)            -6.7456826  2.4922534  -2.707  0.00680 **  ## mean_rh                 0.1750779  0.0437951   3.998 6.40e-05 *** ## total_rain              0.0287701  0.0102161   2.816  0.00486 **  ## mean_wd                -0.0001317  0.0019612  -0.067  0.94647     ## mean_ws                 0.5106963  1.4771096   0.346  0.72954     ## mean_temp              -0.3977193  0.0852342  -4.666 3.07e-06 *** ## lwd_duration           -0.1057611  0.0239992  -4.407 1.05e-05 *** ## locationLowgap          1.3460468  0.4700772   2.863  0.00419 **  ## mean_wd:mean_ws         0.0050870  0.0085342   0.596  0.55113     ## mean_temp:lwd_duration  0.0060753  0.0011822   5.139 2.76e-07 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":[]},{"path":"/articles/a_02_Fit_GLMMs.html","id":"simulate-model-residuals","dir":"Articles","previous_headings":"Model Diagnostics","what":"Simulate model residuals","title":"Fit GLMMs","text":"Check model met data assumptions, model predictions can trusted.","code":"simulateResiduals(mod_7, plot = T, quantreg = T) ## Object of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help.  ##   ## Scaled residual values: 0.06916953 0.3061759 0.1201552 0.4451339 0.9662278 0.3547005 0.4547746 0.1893003 0.9241854 0.688 0.652516 0.1541348 0.2992751 0.4713096 0.6199157 0.5902045 0.944 0.444 0.708 0.7273926 ..."},{"path":"/articles/a_02_Fit_GLMMs.html","id":"plot-model","dir":"Articles","previous_headings":"Model Diagnostics","what":"Plot model","title":"Fit GLMMs","text":"Plot main effects weather variables using ggplot2","code":"# Relative humidity graph p1 <- ggpredict(mod_7, \"mean_rh[56:96]\",                 type = \"random\") %>%   as.data.frame() %>%   rename(mean_rh = x, total_count = predicted) %>%   mutate(mean_rh = as.numeric(as.character(mean_rh))) %>%   ggplot(aes(mean_rh, total_count)) +   geom_line() +   geom_ribbon(colour = NA,               alpha = 0.1,               aes(ymin = conf.low, ymax = conf.high)) +   geom_point(data = dat_nc_ncb,              size = 1) +   annotate(\"text\",            x = 80,            y = 500,            label = \"p=0.0001\") +   # scale_color_distiller(palette = \"Spectral\") +   # scale_fill_distiller(palette = \"Spectral\", guide = \"none\") +   #coord_cartesian(ylim = range(dat_nc_ncb$total_count), xlim = range(dat_nc_ncb$mean_rh)) +   coord_cartesian(ylim = c(0, 690)) +   #scale_y_continuous(trans = \"log1p\") +   theme_few(base_size = 11) +   labs(x = \"Mean RH (%)\", y = \"Number of infected leaves\")  p1 # Rainfall graph p2 <- ggpredict(mod_7, \"total_rain[0:135]\",                 type = \"random\") %>%   as.data.frame() %>%   rename(total_rain = x, total_count = predicted) %>%   #mutate(total_rain= as.numeric(as.character(total_rain))) %>%   ggplot(aes(total_rain, total_count)) +   geom_line() +   geom_point(data = dat_nc_ncb,              size = 1) +   geom_ribbon(     colour = NA,     fill = \"black\",     alpha = 0.1,     aes(ymin = conf.low, ymax = conf.high)   ) +   annotate(\"text\",            x = 80,            y = 500,            label = \"p=0.0049\") +   # scale_color_distiller(palette = \"Spectral\") +   # scale_fill_distiller(palette = \"Spectral\", guide = \"none\") +   #coord_cartesian(ylim = range(dat_nc_ncb$total_count), xlim = range(dat_nc_ncb$mean_rh)) +   coord_cartesian(ylim = c(0, 690), xlim = c(0, 135)) +   theme_few(base_size = 11) +   labs(x = \"Total rain (mm)\", y = \"\")  p2 fig_3 <- p1 + p2 + plot_layout(tag_level = 'new') +   plot_annotation(tag_levels = list(c('(a)', '(b)'))) &     theme(plot.tag = element_text(face = 'bold', size = 11))"},{"path":"/articles/a_02_Fit_GLMMs.html","id":"plot-interaction-effect-using-ggplot2","dir":"Articles","previous_headings":"Model Diagnostics","what":"Plot interaction effect using ggplot2","title":"Fit GLMMs","text":"","code":"fig_4 <- ggpredict(mod_7, terms = c(\"lwd_duration[1:160]\", \"mean_temp[10:27]\"), type = \"random\") %>%     as.data.frame() %>%     rename(lwd_duration = x, mean_temp = group, total_count = predicted) %>%     mutate(mean_temp = as.numeric(as.character(mean_temp))) ggplot() +     geom_line(data = fig_4, aes(lwd_duration, total_count, color = mean_temp, group = mean_temp), alpha = 0.8) +     geom_point(data = dat_nc_ncb, aes(x = lwd_duration, y = total_count, fill = mean_temp), shape = 21, color = \"black\", size = 2.5) +     scale_color_distiller(palette = \"Spectral\") +     scale_fill_distiller(palette = \"Spectral\", guide = \"none\") +    coord_cartesian(ylim=c(0, 690),xlim = c(1,160)) +     annotate(\"text\", x=80, y=500, label= \"p=0.0001\") +     theme_few(base_size = 11) +     labs(x = \"Leaf Wetness Duration\", y = \"Number of Infected Leaves\", color = \"Mean Temperature (°C)\")"},{"path":"/articles/a_03_BBIRM.html","id":"import-disease-data-data","dir":"Articles","previous_headings":"","what":"Import disease data data","title":"Boxwood blight infection risk model","text":"Import disease data recorded Lowgap & Lamsburg sites","code":"disease_dat <- read_excel(system.file(   \"extdata\",   \"NC_disease_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(replicate = as.factor(replicate)) %>%   dplyr::mutate(treatment = as.factor(treatment)) %>%   dplyr::mutate(total_count = as.integer(total_count)) %>%   dplyr::mutate(month = as.factor(months(date_in))) %>%   dplyr::mutate(spev_duration = as.integer(difftime(date_out, date_in))) %>%   relocate(month, .after = date_out) %>%   na.omit() %>%   group_by(     year,     location,     spread_event,     month,     treatment,     date_in,     date_out,     cultivar,     spev_duration   ) %>%   summarise(total_count = sum(total_count)) ## `summarise()` has grouped output by 'year', 'location', 'spread_event', ## 'month', 'treatment', 'date_in', 'date_out', 'cultivar'. You can override using ## the `.groups` argument."},{"path":"/articles/a_03_BBIRM.html","id":"import-weather-data","dir":"Articles","previous_headings":"","what":"Import weather data","title":"Boxwood blight infection risk model","text":"","code":"# Filter rainy periods to calculate average wind speed, wind direction & temperature wet period weather_dat_rain <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   select(year,          wind_speed,          wind_direction,          temperature,          precipitation,          location,          spread_event) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   dplyr::mutate(rain_duration = as.integer(precipitation > 0)) %>%   filter(precipitation > 0) %>%   group_by(year, location, spread_event) %>%   summarise(     total_rain = round(sum(precipitation), 5),     mean_ws = round(mean(wind_speed), 2),     rain_duration = round(sum(rain_duration * 15 / 60), 2),     mean_wd = round(circular.averaging(wind_direction), 2),     mean_temp = round(mean(temperature), 2)   )  # Filter rainless periods to calculate mean RH weather_dat_no_rain <-   read_excel(system.file(     \"extdata\",     \"NC_weather_data.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   )) %>%   select(     year,     relative_humidity,     leaf_wetness_duration,     precipitation,     location,     spread_event,     date   ) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   filter(precipitation == 0) %>%   group_by(year, location, spread_event) %>%   summarise(mean_rh = round(mean(relative_humidity * 100), 2))  # Combine data weather_dat_comb <-   left_join(weather_dat_rain,             weather_dat_no_rain,             by = c(\"year\", \"location\", \"spread_event\"))  # Leaf wetness duration both inside and outside rainy periods weather_wet <- read_excel(system.file(   \"extdata\",   \"NC_weather_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event)) %>%   group_by(year, location, spread_event) %>%   summarise(lwd_duration = round(sum(leaf_wetness_duration / 60), 2))  weather_dat <-   left_join(weather_dat_comb,             weather_wet,             by = c(\"year\", \"location\", \"spread_event\"))  # Divide week 1 of 2014 rain/rain duration/wetness duration by 4 & that of week 2 & 3 by 3 to convert to per week data because the duration of spread event was 4 and 3 weeks, respectively.  weather_dat <- weather_dat %>%   mutate(     total_rain = ifelse(       year == \"2017\" & spread_event == \"1\",       total_rain / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         total_rain / 3,         total_rain       )     ),     rain_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       rain_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         rain_duration / 3,         rain_duration       )     ),     lwd_duration = ifelse(       year == \"2017\" & spread_event == \"1\",       lwd_duration / 4,       ifelse(         year == \"2017\" &           spread_event %in% c(\"2\", \"3\"),         lwd_duration / 3,         lwd_duration       )     )   )"},{"path":"/articles/a_03_BBIRM.html","id":"cobmine-weather-disease-data","dir":"Articles","previous_headings":"","what":"Cobmine weather & disease data","title":"Boxwood blight infection risk model","text":"Combine weather disease data","code":"dat_NC <-   left_join(disease_dat,             weather_dat,             by = c(\"year\", \"location\", \"spread_event\")) %>%   # Replace NA with zero because NA are introduced due to data munging. Original values were zero   dplyr::mutate(total_rain = replace_na(total_rain, 0)) %>%   dplyr::mutate(rain_duration = replace_na(rain_duration, 0))  # Since we filtered data separately for precipitation and then without precipitation, NAs are introduced. In this step, data (in which values were added manually) is imported  dat_missing <- read_excel(system.file(   \"extdata\",   \"NC_missing_data.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%   dplyr::mutate(year = as.factor(year)) %>%   dplyr::mutate(location = as.factor(location)) %>%   dplyr::mutate(spread_event = as.factor(spread_event))  # Combine data to replace NA values with distinct data dat_nc <-   left_join(dat_NC, dat_missing, by = c(\"year\", \"location\", \"spread_event\")) %>%   mutate(mean_ws = coalesce(mean_ws.x, mean_ws.y)) %>%   select(-mean_ws.x, -mean_ws.y) %>%   mutate(mean_temp = coalesce(mean_temp.x, mean_temp.y)) %>%   select(-mean_temp.x, -mean_temp.y) %>%   mutate(mean_rh = coalesce(mean_rh.x, mean_rh.y)) %>%   select(-mean_rh.x, -mean_rh.y) %>%   mutate(mean_wd = coalesce(mean_wd.x, mean_wd.y)) %>%   select(-mean_wd.x, -mean_wd.y) %>%   mutate(lwd_duration = coalesce(lwd_duration.x, lwd_duration.y)) %>%   select(-lwd_duration.x, -lwd_duration.y) %>%   distinct()  dat_nc <- dat_nc %>%   mutate(daily_rain = round(total_rain/spev_duration, 2),          daily_lwd  = round(lwd_duration/spev_duration, 2))    # Filter out mulch treatment. Use non-mulch and CP only. dat_nc_ncb <- dat_nc %>%   filter(treatment != \"mulch\", treatment != \"between_row\") # filter non-mulch, CP and between row treatments data  # Data considering only CP treatment dat_cp <- dat_nc %>%   filter(treatment == \"CP\")  # Data considering only leaf debris treatment dat_ld <- dat_nc %>%   filter(treatment == \"non_mulch\")  # Data considering only between row treatment dat_br <- dat_nc %>%   filter(treatment == \"between_row\")  # Data for Lambsburg site only dat_lambsburg <- dat_nc %>%   filter(location == \"Lambsburg\") %>%   filter(treatment != \"mulch\", treatment != \"between_row\")"},{"path":"/articles/a_03_BBIRM.html","id":"boxwood-blight-infection-risk-model","dir":"Articles","previous_headings":"","what":"Boxwood blight infection risk model","title":"Boxwood blight infection risk model","text":"Run Boxwood blight infection risk model. SENSOR-ADJ version model uses leaf wetness recorded leaf wetness sensor","code":"base_temperature <- 44   lookup_table <- read_excel(system.file(   \"extdata\",   \"lookup_table.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE ))      # WARNING: Double check for index_new (lookup_table) and index_anton (same but proportional wetness)   index <- read_excel(system.file(   \"extdata\",   \"hourly_df_index_new.xlsx\",   package = \"epiboxwoodblight\",   mustWork = TRUE )) %>%  mutate(dry_hour_count = ifelse(lwd_duration == 0, sequence(rle(lwd_duration == 0)$lengths), 0)) %>%   mutate(mean_temp_f = round(mean_temp_f)) %>%   mutate(zero_index = lwd_duration == 0 | dry_hour_count > 5 | mean_temp_f < 44 | mean_temp_f > 86) %>%   group_by(year, location, spread_event, cumsum(dry_hour_count > 5)) %>%   # model version 1   mutate(index_new = cumsum(ifelse(zero_index, 0, mean_temp_f - base_temperature))) %>%    relocate(index, .before = index_new) %>%   left_join(lookup_table, by = \"mean_temp_f\") %>%   # model version 3   mutate(index_new = cumsum(ifelse(zero_index, 0, index_lookup))) %>%    mutate(index_new_anton = cumsum(ifelse(zero_index, 0, index_lookup) * lwd_duration / 60)) %>% # Proportional leaf wetness suggested by Anton   mutate(dhs_exceeding_250_anton = ifelse(index_new_anton >= 250, TRUE, FALSE),          index_rs_hour = ifelse(index_new_anton > 0, index_new_anton - lag(index_new_anton, default = 0), 0)) %>%   select(-`cumsum(dry_hour_count > 5)`, -zero_index)    # Find maximum value of index and whether disease is predicted or not, and combine with the data  index_cap <- index %>%   group_by(year, location, spread_event) %>%   summarise(max_index_value_rs = round(max(index_new_anton)),             disease_predicted_rs = ifelse(any(index_new_anton>= 250), 1, 0),              index_rs_week = round(sum(index_rs_hour)))     index <- left_join(index, index_cap, by = c(\"year\", \"location\", \"spread_event\")) %>%     mutate(year = as.factor(year), spread_event = as.factor(spread_event))   # Finally, combine disease data with the index table   # Disease data ncncb <- dat_nc_ncb %>%   select(spread_event, year, location, total_count) %>%   mutate(year = as.factor(year), spread_event = as.factor(spread_event)) %>%   group_by(year, location, spread_event) %>%   summarise(total_count_index = sum(total_count),             epidemic_week = ifelse(total_count>298, \"Yes\", \"No\"))    index <- left_join(index, ncncb, by = c(\"year\", \"location\", \"spread_event\")) %>%    mutate(year = as.factor(year), spread_event = as.factor(spread_event))"},{"path":"/articles/a_03_BBIRM.html","id":"model-comparison","dir":"Articles","previous_headings":"","what":"Model comparison","title":"Boxwood blight infection risk model","text":"Compare model using three different leaf wetness criteria. lws represents SENSOR model rs represents SENSOR-ADJ model nlws represents ESTIM-LW model","code":"# Import data and calculate hourly and weekly index comparison_dat1 <- read_excel(   system.file(     \"extdata\",     \"Indices_validation_data_new.xlsx\",     package = \"epiboxwoodblight\",     mustWork = TRUE   ) ) %>%   mutate(year = as.factor(year)) %>%   mutate(location = as.factor(location)) %>%   mutate(week = as.factor(week)) %>%   group_by(year, location, week) %>%   mutate(     index_lws_hour = ifelse(index_lws > 0, index_lws - lag(index_lws, default = 0), 0),     index_lws_week = sum(index_lws_hour),     disease_predicted_lws = ifelse(any(index_lws >= 250), \"Yes\", \"No\"),     max_index_value_lws = max(index_lws),     index_nlws_hour = ifelse(index_nlws > 0, index_nlws - lag(index_nlws, default = 0), 0),     disease_predicted_nlws = ifelse(any(index_nlws >= 250), \"Yes\", \"No\"),     max_index_value_nlws = max(index_nlws),     index_nlws_week = sum(index_nlws_hour)   ) %>%   ungroup()  #openxlsx::write.xlsx(comparison_dat1, \"indices_lc.xlsx\")  comparison_dat2 <- comparison_dat1 %>%   group_by(year, location, week) %>%   summarise(     disease_predicted_lws = ifelse(any(index_lws >= 250), 1, 0),     max_index_value_lws = max(index_lws),     max_index_value_nlws = max(index_nlws),     index_lws_week = sum(index_lws_hour),     index_nlws_week = sum(index_nlws_hour),     disease_predicted_nlws = ifelse(any(index_nlws >= 250), 1, 0)   ) %>%   ungroup()   # Disease data ncncb <- dat_nc %>%   filter(treatment != \"mulch\") %>%   rename(week = spread_event) %>%   group_by(year, location, week) %>%   summarise(     disease_recorded_detector_plants = ifelse(any(total_count > 0), 1, 0),     total_count = sum(total_count)   )   comparison_dat3 <-   left_join(comparison_dat2, ncncb, by = c(\"year\", \"location\", \"week\"))  # Join index that was re-started each week index_rs <- index_cap %>%   rename(week = spread_event) %>%   mutate(year = as.factor(year),          week = as.factor(week))  comparison_dat4 <-   left_join(comparison_dat3, index_rs, by = c(\"year\", \"location\", \"week\"))"},{"path":[]},{"path":"/articles/a_03_BBIRM.html","id":"glms","dir":"Articles","previous_headings":"Totat weekly accumulated blight risk index & infected leaf count relationship","what":"GLMs","title":"Boxwood blight infection risk model","text":"","code":"set.seed(42)  dat_2014 <- comparison_dat4 %>%   filter(year==2014)  dat_2015 <- comparison_dat4 %>%   filter(year==2015)  dat_2016 <- comparison_dat4 %>%   filter(year==2016)  dat_2017 <- comparison_dat4 %>%   filter(year==2017)  # Fit & plot LWS models for each year lws_2014 <- glm(total_count ~ index_lws_week, family = quasipoisson, data= dat_2014)  summary(lws_2014) ##  ## Call: ## glm(formula = total_count ~ index_lws_week, family = quasipoisson,  ##     data = dat_2014) ##  ## Deviance Residuals:  ##      Min        1Q    Median        3Q       Max   ## -15.0445   -7.9139   -5.2653   -0.4034   26.2879   ##  ## Coefficients: ##                 Estimate Std. Error t value Pr(>|t|)   ## (Intercept)    2.2379339  0.9484794   2.359   0.0298 * ## index_lws_week 0.0010134  0.0003597   2.817   0.0114 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 158.4062) ##  ##     Null deviance: 3507.2  on 19  degrees of freedom ## Residual deviance: 2202.2  on 18  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_lws_2014 <- with(summary(lws_2014), 1 - deviance/null.deviance)   lws_2015 <- glm(total_count ~ index_lws_week, family = quasipoisson, data= dat_2015)  summary(lws_2015) ##  ## Call: ## glm(formula = total_count ~ index_lws_week, family = quasipoisson,  ##     data = dat_2015) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -18.438   -9.262   -6.074    3.491   40.719   ##  ## Coefficients: ##                 Estimate Std. Error t value Pr(>|t|)     ## (Intercept)    2.8726576  0.6883836   4.173  0.00034 *** ## index_lws_week 0.0014324  0.0003634   3.942  0.00061 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 235.5526) ##  ##     Null deviance: 7584.1  on 25  degrees of freedom ## Residual deviance: 4010.6  on 24  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_lws_2015 <- with(summary(lws_2015), 1 - deviance/null.deviance)    lws_2016 <- glm(total_count ~ index_lws_week, family = quasipoisson, data= dat_2016)  summary(lws_2016) ##  ## Call: ## glm(formula = total_count ~ index_lws_week, family = quasipoisson,  ##     data = dat_2016) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -11.048   -9.626   -8.385   -7.127   43.574   ##  ## Coefficients: ##                 Estimate Std. Error t value Pr(>|t|)    ## (Intercept)    3.6805521  1.0068709   3.655  0.00139 ** ## index_lws_week 0.0002833  0.0005771   0.491  0.62834    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 341.6754) ##  ##     Null deviance: 4096.4  on 23  degrees of freedom ## Residual deviance: 4011.3  on 22  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_lws_2016 <- with(summary(lws_2016), 1 - deviance/null.deviance)   lws_2017 <- glm(total_count ~ index_lws_week, family = quasipoisson, data= dat_2017)  summary(lws_2017) ##  ## Call: ## glm(formula = total_count ~ index_lws_week, family = quasipoisson,  ##     data = dat_2017) ##  ## Deviance Residuals:  ##      Min        1Q    Median        3Q       Max   ## -13.5926   -5.4541   -2.6242    0.2849   14.0736   ##  ## Coefficients: ##                  Estimate Std. Error t value Pr(>|t|)   ## (Intercept)    -1.4801073  2.1115755  -0.701   0.4948   ## index_lws_week  0.0021936  0.0009327   2.352   0.0338 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 47.68894) ##  ##     Null deviance: 950.55  on 15  degrees of freedom ## Residual deviance: 666.81  on 14  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 7 #calculate McFadden's R-squared for model r_squared_lws_2017 <- with(summary(lws_2017), 1 - deviance/null.deviance)  # plot all LWS models  Lws_1 <-   plot(ggpredict(lws_2014, \"index_lws_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"Number of infected leaves\", title = 2014) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.37\", \"p=0.0114\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank()) +  theme(aspect.ratio = 1)    Lws_2 <-   plot(ggpredict(lws_2015, \"index_lws_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"\", title = 2015) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.47\", \"p=0.0006\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank(),         axis.text.y = element_blank()) +   theme(aspect.ratio = 1)    Lws_3 <-   plot(ggpredict(lws_2016, \"index_lws_week\"), rawdata = TRUE) +   labs(x = \"LWS model\", y = \"\", title = 2016) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.02\", \"p=0.6283\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5)) +  theme(aspect.ratio = 1)     Lws_4 <-   plot(ggpredict(lws_2017, \"index_lws_week\"), rawdata = TRUE) +   labs(x = \"LWS model\", y = \"\", title = 2017) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.3\", \"p=0.0338\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.y = element_blank()) +    theme(aspect.ratio = 1)        lws_plots <- (Lws_1 +Lws_2)/ (Lws_3+ Lws_4) +    plot_layout(widths = c(1, 1), heights = c(1, 1))   # Fit and plot NLWS models for each year & then combine plots for all four years  nlws_2014 <- glm(total_count ~ index_nlws_week, family = quasipoisson, data= dat_2014)  summary(nlws_2014) ##  ## Call: ## glm(formula = total_count ~ index_nlws_week, family = quasipoisson,  ##     data = dat_2014) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -13.057  -10.599   -8.280   -3.207   32.476   ##  ## Coefficients: ##                  Estimate Std. Error t value Pr(>|t|)   ## (Intercept)     2.7088248  1.4978372   1.808   0.0873 . ## index_nlws_week 0.0006264  0.0005147   1.217   0.2393   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 255.947) ##  ##     Null deviance: 3507.2  on 19  degrees of freedom ## Residual deviance: 3053.4  on 18  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 7 #calculate McFadden's R-squared for model r_squared_nlws_2014 <- with(summary(nlws_2014), 1 - deviance/null.deviance)   nlws_2015 <- glm(total_count ~ index_nlws_week, family = quasipoisson, data= dat_2015)  summary(nlws_2015) ##  ## Call: ## glm(formula = total_count ~ index_nlws_week, family = quasipoisson,  ##     data = dat_2015) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -24.746  -12.699   -7.057    3.373   37.809   ##  ## Coefficients: ##                  Estimate Std. Error t value Pr(>|t|)   ## (Intercept)     2.2758071  1.2100757   1.881   0.0722 . ## index_nlws_week 0.0010608  0.0004427   2.396   0.0247 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 270.8002) ##  ##     Null deviance: 7584.1  on 25  degrees of freedom ## Residual deviance: 5715.7  on 24  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_nlws_2015 <- with(summary(nlws_2015), 1 - deviance/null.deviance)    nlws_2016 <- glm(total_count ~ index_nlws_week, family = quasipoisson, data= dat_2016)  summary(nlws_2016) ##  ## Call: ## glm(formula = total_count ~ index_nlws_week, family = quasipoisson,  ##     data = dat_2016) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -11.225   -9.305   -8.120   -6.792   43.554   ##  ## Coefficients: ##                  Estimate Std. Error t value Pr(>|t|)    ## (Intercept)     3.6027154  1.0619616   3.393  0.00262 ** ## index_nlws_week 0.0002467  0.0004493   0.549  0.58844    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 341.3815) ##  ##     Null deviance: 4096.4  on 23  degrees of freedom ## Residual deviance: 3989.2  on 22  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 7 #calculate McFadden's R-squared for model r_squared_nlws_2016 <- with(summary(nlws_2016), 1 - deviance/null.deviance)   nlws_2017 <- glm(total_count ~ index_nlws_week, family = quasipoisson, data= dat_2017)  summary(nlws_2017) ##  ## Call: ## glm(formula = total_count ~ index_nlws_week, family = quasipoisson,  ##     data = dat_2017) ##  ## Deviance Residuals:  ##      Min        1Q    Median        3Q       Max   ## -12.7142   -4.7841   -3.5733   -0.3992   13.9502   ##  ## Coefficients: ##                   Estimate Std. Error t value Pr(>|t|)   ## (Intercept)     -0.0641031  1.7630515  -0.036   0.9715   ## index_nlws_week  0.0011282  0.0005759   1.959   0.0703 . ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 58.10312) ##  ##     Null deviance: 950.55  on 15  degrees of freedom ## Residual deviance: 735.59  on 14  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 7 #calculate McFadden's R-squared for model r_squared_nlws_2017 <- with(summary(nlws_2017), 1 - deviance/null.deviance)  # plot all NLWS models Nlws_1 <-   plot(ggpredict(nlws_2014, \"index_nlws_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"\", title = 2014) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.13\", \"p=0.2393\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank(),         axis.text.y = element_blank()) +      theme(aspect.ratio = 1)    Nlws_2 <-   plot(ggpredict(nlws_2015, \"index_nlws_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"\", title = 2015) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.25\", \"p=0.0247\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank(),         axis.text.y = element_blank()) +      theme(aspect.ratio = 1)    Nlws_3 <-   plot(ggpredict(nlws_2016, \"index_nlws_week\"), rawdata = TRUE) +   labs(x = \"NLWS model\", y = \"\", title = 2016) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.03\", \"p=0.5884\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.y = element_blank()) +      theme(aspect.ratio = 1)    Nlws_4 <-   plot(ggpredict(nlws_2017, \"index_nlws_week\"), rawdata = TRUE) +   labs(x = \"NLWS model\", y = \"\", title = 2017) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.23\", \"p=0.0703\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.y = element_blank()) +      theme(aspect.ratio = 1)    Nlws_plots <- (Nlws_1 +Nlws_2)/ (Nlws_3+ Nlws_4) +   plot_layout(widths = c(1, 1), heights = c(1, 1))  # Nlws_plots <- annotate_figure(Nlws_plots, left = textGrob(\"Number of infected leaves\", rot = 90, vjust = 1), bottom = textGrob(\"\"))     # Fit and plot RS models for each year & then combine plots for all four years  rs_2014 <- glm(total_count ~ index_rs_week, family = quasipoisson, data= dat_2014)  summary(rs_2014) ##  ## Call: ## glm(formula = total_count ~ index_rs_week, family = quasipoisson,  ##     data = dat_2014) ##  ## Deviance Residuals:  ##      Min        1Q    Median        3Q       Max   ## -14.9030   -7.9578   -5.0701   -0.4303   25.8995   ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)    ## (Intercept)   2.1682356  0.9466880   2.290  0.03429 *  ## index_rs_week 0.0010756  0.0003692   2.913  0.00927 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 151.4254) ##  ##     Null deviance: 3507.2  on 19  degrees of freedom ## Residual deviance: 2149.0  on 18  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_rs_2014 <- with(summary(rs_2014), 1 - deviance/null.deviance)   rs_2015 <- glm(total_count ~ index_rs_week, family = quasipoisson, data= dat_2015)  summary(rs_2015) ##  ## Call: ## glm(formula = total_count ~ index_rs_week, family = quasipoisson,  ##     data = dat_2015) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -18.831   -9.250   -5.709    2.297   39.880   ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)     ## (Intercept)   2.9260693  0.6517106   4.490 0.000152 *** ## index_rs_week 0.0014397  0.0003489   4.127 0.000383 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 225.8005) ##  ##     Null deviance: 7584.1  on 25  degrees of freedom ## Residual deviance: 3916.6  on 24  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_rs_2015 <- with(summary(rs_2015), 1 - deviance/null.deviance)    rs_2016 <- glm(total_count ~ index_rs_week, family = quasipoisson, data= dat_2016)  summary(rs_2016) ##  ## Call: ## glm(formula = total_count ~ index_rs_week, family = quasipoisson,  ##     data = dat_2016) ##  ## Deviance Residuals:  ##     Min       1Q   Median       3Q      Max   ## -11.238   -9.541   -8.301   -6.973   43.439   ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)    ## (Intercept)   3.6485311  1.0126663   3.603  0.00158 ** ## index_rs_week 0.0003176  0.0006015   0.528  0.60280    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 338.8323) ##  ##     Null deviance: 4096.4  on 23  degrees of freedom ## Residual deviance: 3998.0  on 22  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_rs_2016 <- with(summary(rs_2016), 1 - deviance/null.deviance)   rs_2017 <- glm(total_count ~ index_rs_week, family = quasipoisson, data= dat_2017)  summary(rs_2017) ##  ## Call: ## glm(formula = total_count ~ index_rs_week, family = quasipoisson,  ##     data = dat_2017) ##  ## Deviance Residuals:  ##      Min        1Q    Median        3Q       Max   ## -14.0856   -4.8697   -2.1900    0.3873   11.9836   ##  ## Coefficients: ##                 Estimate Std. Error t value Pr(>|t|)   ## (Intercept)   -2.3052474  2.0869813  -1.105   0.2880   ## index_rs_week  0.0026681  0.0009413   2.835   0.0132 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for quasipoisson family taken to be 38.11435) ##  ##     Null deviance: 950.55  on 15  degrees of freedom ## Residual deviance: 592.01  on 14  degrees of freedom ## AIC: NA ##  ## Number of Fisher Scoring iterations: 6 #calculate McFadden's R-squared for model r_squared_rs_2017 <- with(summary(rs_2017), 1 - deviance/null.deviance)  # plot all NLWS models rs_1 <-   plot(ggpredict(rs_2014, \"index_rs_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"\", title = 2014) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.39\", \"p=0.0092\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank(),         axis.text.y = element_blank()) +       theme(aspect.ratio = 1)    rs_2 <-   plot(ggpredict(rs_2015, \"index_rs_week\"), rawdata = TRUE) +   labs(x = \"\", y = \"\", title = 2015) +   coord_cartesian(ylim = c(0, 1000), xlim = c(0, 3000)) +    annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.48\", \"p=0.0003\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.x = element_blank(),         axis.text.y = element_blank()) +       theme(aspect.ratio = 1)    rs_3 <-   plot(ggpredict(rs_2016, \"index_rs_week\"), rawdata = TRUE) +   labs(x = \"RS model\", y = \"\", title = 2016) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.02\", \"p=0.6028\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.y = element_blank()) +       theme(aspect.ratio = 1)     rs_4 <-   plot(ggpredict(rs_2017, \"index_rs_week\"), rawdata = TRUE) +   labs(x = \"RS model\", y = \"\", title = 2017) +   coord_cartesian(ylim=c(0, 1000),xlim = c(0, 3000)) +   annotate(\"text\",            x = c(750, 750),            y = c(700, 800),            label =c(\"R²= 0.38\", \"p=0.0132\")) +   theme_few() +   theme(plot.title = element_text(hjust = 0.5),         axis.text.y = element_blank()) +       theme(aspect.ratio = 1)    rs_plots <- (rs_1 + rs_2)/ (rs_3+ rs_4) +   plot_layout(widths = c(1, 1), heights = c(1, 1))  # rs_plots <- annotate_figure(rs_plots, left = textGrob(\"Number of infected leaves\", rot = 90, vjust = 1))   fig_index_lesions <- wrap_plots(lws_plots, Nlws_plots, rs_plots)       ggsave(     here(\"man\", \"figures/fig_index_lesions.png\"),     plot = fig_index_lesions,     width = 14,     height = 6,     units = \"in\",     dpi = 600   )    fig_index_lesions"},{"path":"/articles/a_03_BBIRM.html","id":"plot-total-weekly-accumulated-blight-risk-index-values","dir":"Articles","previous_headings":"Totat weekly accumulated blight risk index & infected leaf count relationship","what":"Plot total weekly accumulated blight risk index values","title":"Boxwood blight infection risk model","text":"","code":"dat_weeeek <- dat_nc_ncb %>%   mutate(date_in = format(date_in, \"%m/%d\")) %>%   group_by(year, date_in) %>%   arrange(year, date_in, total_count) %>%   ungroup() %>%   mutate(date_in = as.factor(date_in)) %>%   mutate(treatment = recode(treatment,                             \"CP\" = \"Infected canopies\",                             \"non_mulch\" = \"Leaf debris\")) %>%   rename(\"Inoculum source\" = treatment) %>%   select(date_in,          year,          location,          spread_event,          total_count,          `Inoculum source`)     comparison_dat_6 <- comparison_dat4 %>%   rename(spread_event = week) %>%   pivot_longer(     cols = c(\"index_lws_week\",              \"index_nlws_week\",              \"index_rs_week\"),     names_to = \"Model\",     values_to = \"index_weekly_value\"   )  index_dfff <- comparison_dat_6 %>%   mutate(     Model = recode(       Model,       \"index_rs_week\" = \"SENSOR-ADJ model\",       \"index_lws_week\" = \"SENSOR model\",       \"index_nlws_week\" = \"ESTIM-LW model\"     )   )   dat_week <-   left_join(dat_weeeek,             index_dfff,             by = c(\"year\", \"location\", \"spread_event\")) %>%   distinct(year, location, spread_event, Model, .keep_all = TRUE)  openxlsx::write.xlsx(dat_week, \"check.xlsx\")  dates_weeks <- dat_week |>   mutate(date = mdy(paste0(date_in, year)),          week = week(date)) %>%   mutate(week = ifelse(year == 2015 & spread_event == 24, 43, week))    min_week <- min(dates_weeks$week) max_week <- max(dates_weeks$week)  year_breaks <- 2017:2014 |>   set_names() |>   map(\\(year_n) {     year_dat <- dates_weeks |>       filter(year == year_n) |>       select(date_in, week) |>       unique()          week_map <- character(max_week - min_week + 1)     names(week_map) <- seq(min_week, max_week)          week_map[as.character(year_dat$week)] <-       as.character(year_dat$date_in)               week_map        })   p <- dates_weeks |>   mutate(week = factor(week),          `Inoculum source` = factor(`Inoculum source`)) |>   nest(data = -year) |>   mutate(pl = map2(data, year, \\(data, year) {     # browser()          ggplot(data, aes(x = week, y = index_weekly_value, fill = Model)) +       geom_col(position = position_dodge(width = 0.7)) +       coord_cartesian(ylim = c(4, 8603)) +       # scale_y_continuous(breaks = seq(0, 334305, length.out = 5), limits = c(0, 334305),       #                      labels = function(x) sprintf(\"%.0f\", x)) +       scale_x_discrete(labels = year_breaks[[as.character(year)]],                        drop = FALSE) +       facet_wrap(year, scales = \"free_y\", strip.position = \"right\") +       #  scale_fill_manual(values = c(       #   \"max_index_value_rs\"= \"navyblue\",       #   \"max_index_value_lws\" = \"green\",       #    \"max_index_value_nlws\"= \"darkred\"       # )) +       scale_fill_viridis_d(option = \"cividis\") +       theme_few(base_size = 10)             })) |>   pull(pl) |>   wrap_plots(ncol = 1) +   plot_layout(guides = \"collect\") & xlab(NULL) & ylab(NULL) &   theme(     legend.position = \"top\",     axis.text.x = element_text(       angle = 90,       hjust = 1,       vjust = 0.5,       color = \"black\"     ),     axis.text.y = element_text(vjust = 0.5, color = \"black\"),     axis.title = element_text(color = \"black\"),     strip.text = element_text(face = \"bold\", color = \"black\")        )   p <-   p + labs(x = \"Date of detector plants placement in the field\") +   theme(axis.title.x = element_text(hjust = 0.5))  # Center x-axis label   p_sum_index <- wrap_elements(p) +   labs(tag = \"Total weekly accumulated blight risk index\") +   theme(plot.tag = element_text(size = rel(1), angle = 90),         plot.tag.position = \"left\")    ggsave(   here(\"man\", \"figures/p_sum_index.png\"),   plot = p_sum_index,   width = 7,   height = 7,   units = \"in\",   dpi = 1000 )  ggsave(   here(\"man\", \"figures/p_sum_index.eps\"),   plot = p_sum_index,   width = 7,   height = 7,   units = \"in\",   dpi = 600,   device =  cairo_ps )  p_sum_index"},{"path":[]},{"path":[]},{"path":"/articles/a_03_BBIRM.html","id":"confusion-matrices","dir":"Articles","previous_headings":"Quantitative comparison of the model using different leaf wetness criteria","what":"Confusion matrices","title":"Boxwood blight infection risk model","text":"","code":"disease_predicted_lws <-   factor(comparison_dat4$disease_predicted_lws) disease_predicted_nlws <-   factor(comparison_dat4$disease_predicted_nlws) disease_predicted_rs <- factor(comparison_dat4$disease_predicted_rs) disease_recorded <-   factor(comparison_dat4$disease_recorded_detector_plants)  confusion_matrix_lws <-   metrica::confusion_matrix(     obs = disease_recorded,     pred = disease_predicted_lws,     plot = TRUE,     print_metrics = TRUE,     metrics_list = c(\"accuracy\", \"precision\", \"recall\", \"specificity\"),     position_metrics = \"top\",     colors = c(low = \"#1f78b4\", high = \"#33a02c\"),     na.rm = TRUE   )  confusion_matrix_nlws <-   metrica::confusion_matrix(     obs = disease_recorded,     pred = disease_predicted_nlws,     plot = TRUE,     print_metrics = TRUE,     metrics_list = c(\"accuracy\", \"precision\", \"recall\", \"specificity\"),     position_metrics = \"top\",     colors = c(low = \"#1f78b4\", high = \"#33a02c\"),     na.rm = TRUE   )   confusion_matrix_rs <-   metrica::confusion_matrix(     obs = disease_recorded,     pred = disease_predicted_rs,     plot = TRUE,     print_metrics = TRUE,     metrics_list = c(\"accuracy\", \"precision\", \"recall\", \"specificity\"),     position_metrics = \"top\",     colors = c(low = \"#1f78b4\", high = \"#33a02c\"),     na.rm = TRUE   )   fig_matrix <-   confusion_matrix_lws + confusion_matrix_nlws + confusion_matrix_rs + plot_layout(ncol =                                                                                      1, tag_level = 'new') +   plot_annotation(tag_levels = list(c('(A)', '(B)', '(C)')))   fig_matrix"},{"path":"/articles/a_03_BBIRM.html","id":"f1-scores","dir":"Articles","previous_headings":"Quantitative comparison of the model using different leaf wetness criteria","what":"F1 scores","title":"Boxwood blight infection risk model","text":"","code":"# Calculate accuracy accuracy_rs <- mean(disease_predicted_rs == disease_recorded) # Calculate precision precision_rs <-   sum(disease_predicted_rs == 1 &         disease_recorded == 1) / sum(disease_predicted_rs == 1) # Calculate recall recall_rs <-   sum(disease_predicted_rs == 1 &         disease_recorded == 1) / sum(disease_recorded == 1)  # Calculate F1-score f1_score_rs <-   round(2 * (precision_rs * recall_rs) / (precision_rs + recall_rs), 2)"},{"path":"/articles/a_03_BBIRM.html","id":"reciever-operating-characteristics-curve-roc","dir":"Articles","previous_headings":"Quantitative comparison of the model using different leaf wetness criteria","what":"Reciever Operating Characteristics Curve (ROC)","title":"Boxwood blight infection risk model","text":"","code":"roc_lws <-   pROC::roc(as.integer(disease_predicted_lws),             as.integer(disease_recorded)) ## Setting levels: control = 1, case = 2 ## Setting direction: controls < cases roc_plot_lws <-   plot(roc_lws, main = \"ROC curve for index_lws\", col = \"blue\") abline(0, 1, lty = 2, col = \"gray\") roc_nlws <-   pROC::roc(as.integer(disease_predicted_nlws),             as.integer(disease_recorded)) ## Setting levels: control = 1, case = 2 ## Setting direction: controls < cases roc_plot_nlws <-   plot(roc_nlws, main = \"ROC curve for index_nlws\", col = \"blue\") abline(0, 1, lty = 2, col = \"gray\") roc_rs <-   pROC::roc(as.integer(disease_predicted_rs),             as.integer(disease_recorded)) ## Setting levels: control = 1, case = 2 ## Setting direction: controls < cases roc_plot_rs <-   plot(roc_rs, main = \"ROC curve for index_rx\", col = \"blue\") abline(0, 1, lty = 2, col = \"gray\")"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ihsanul Khaliq. Author, maintainer. Herve Avenot. Author. Anton Baudoin. Author. Leonard Coop. Author. Chuanxue Hong. Author. USDA project 2020-51181-32135. Funder. Farm Bill USDA Animal Plant Health Inspection Service. Funder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Khaliq , Avenot H, Baudoin , Coop L, Hong C (2024). epiboxwoodblight: research compendium accompany 'Epidemiology boxwood blight western North Carolina Virginia validation boxwood blight infection risk model'. doi:10.5281/zenodo.12594039, R package version 1.0.1, https://ihsankhaliq.github.io/epiboxwoodblight/.","code":"@Manual{,   title = {{epiboxwoodblight}: A research compendium to accompany 'Epidemiology of boxwood blight in western North Carolina and Virginia and validation of boxwood blight infection risk model'},   author = {Ihsanul Khaliq and Herve Avenot and Anton Baudoin and Leonard Coop and Chuanxue Hong},   year = {2024},   note = {R package version 1.0.1},   url = {https://ihsankhaliq.github.io/epiboxwoodblight/},   doi = {10.5281/zenodo.12594039}, }"},{"path":"/index.html","id":"epidemiolgy-of-boxwood-blight-in-western-north-carolina-and-virginia-and-validation-of-the-boxwood-blight-infection-risk-model","dir":"","previous_headings":"","what":"Research Compendium for the Paper Epidemiology of boxwood blight in hotspots of western North Carolina and Virginia and validation of the boxwood blight infection risk model","title":"Research Compendium for the Paper Epidemiology of boxwood blight in hotspots of western North Carolina and Virginia and validation of the boxwood blight infection risk model","text":"goal project investigate field epidemiology boxwood blight western North Carolina Virginia validate latest Boxwood blight infection risk model field data.","code":""},{"path":"/index.html","id":"abstract","dir":"","previous_headings":"","what":"Abstract","title":"Research Compendium for the Paper Epidemiology of boxwood blight in hotspots of western North Carolina and Virginia and validation of the boxwood blight infection risk model","text":"Boxwood blight highly invasive emerging disease. Since first US report North Carolina Connecticut 2011, boxwood blight spread 30 US states, risking 90% boxwood production. boxwood blight infection risk model developed limited studies controlled environments disease field epidemiology largely unknown. study investigated disease field epidemiology validated model’s prediction using leaf wetness estimated leaf wetness sensor algorithms analysing weekly blight monitoring data collected detector plants exposed prevailing environmental conditions spring fall 2014 2017. Boxwood blight recorded 61 86 weeks, highest infected leaf count recorded late summer early fall. Rainfall, high relative humidity outside rainy periods optimal temperatures prolonged leaf wetness significant positive effect boxwood blight development. Classification analyses showed predictions model using leaf wetness estimated leaf wetness sensor closely aligned observations field. study improved understanding disease field epidemiology, provided leads improve existing model, generated essential knowledge formulating effective strategies blight mitigation.","code":""},{"path":"/index.html","id":"reproducibility-and-data-availability","dir":"","previous_headings":"","what":"Reproducibility and data availability","title":"Research Compendium for the Paper Epidemiology of boxwood blight in hotspots of western North Carolina and Virginia and validation of the boxwood blight infection risk model","text":"analysis packaged fully reproducible. data work included repository “inst/extdata” folder. Code used importing data, data munging, visualisation model fitting available run R Markdown vignettes, including extra instruction space paper. user-friendly website research compendium can accessed via link https://ihsankhaliq.github.io/epiboxwoodblight/ vignettes can accessed “Articles” menu item. archived code data available https://doi.org/10.5281/zenodo.12594039","code":""}]
